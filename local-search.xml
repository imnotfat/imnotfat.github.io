<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>深度揭秘来自未来的缓存——Caffeine</title>
    <link href="/2020/01/18/%E6%B7%B1%E5%BA%A6%E6%8F%AD%E7%A7%98%E6%9D%A5%E8%87%AA%E6%9C%AA%E6%9D%A5%E7%9A%84%E7%BC%93%E5%AD%98%E2%80%94%E2%80%94Caffeine/"/>
    <url>/2020/01/18/%E6%B7%B1%E5%BA%A6%E6%8F%AD%E7%A7%98%E6%9D%A5%E8%87%AA%E6%9C%AA%E6%9D%A5%E7%9A%84%E7%BC%93%E5%AD%98%E2%80%94%E2%80%94Caffeine/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>由于笔者自身水平有限，如果有不对或者任何建议欢迎批评和指正</p><h1 id="Caffeine详解"><a href="#Caffeine详解" class="headerlink" title="Caffeine详解"></a>Caffeine详解</h1><p>Caffeine是一款基于Java8开发的，高性能的，接近最优的本地缓存库，出自于Benjamin Manes大神之手，大家熟悉的Spring4.3+和SpringBoot1.4+缓存的实现便是基于Caffeine。本文将从淘汰策略、过期策略、并发控制等方面为大家揭开Caffeine的神秘面纱。</p><h2 id="淘汰策略（Size-Based）"><a href="#淘汰策略（Size-Based）" class="headerlink" title="淘汰策略（Size-Based）"></a>淘汰策略（Size-Based）</h2><p>&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp缓存命中率是衡量缓存系统优劣的重要指标，缓存通过保存最近使用或经常使用的数据于速度较快的介质中以提高数据的访问速度，缓存空间被填满后，会面临如何选择丢弃数据为新数据腾出空间的问题，因此选择合适的缓存淘汰算法会直接影响缓存的命中率。常用的缓存算法有：</p><ul><li><em>First in first out (FIFO)</em> 顾名思义，就是一个FIFO队列，先进入缓存的先被淘汰，忽略数据访问频率和次数信息。较为原始，命中率很低。</li><li><em>Least recently used (LRU)</em> 最近最少被使用算法，其核心思想是【如果数据最近被访问过，那么将来被访问的概率也更大】，忽略了数据的访问次数，最常见的实现是维护一个链表，新数据插入到链表尾部，命中缓存的数据重新移至队尾，队列满后移出队首元素。LRU算法在有热点数据的情况下效率很好，但是如果面临突然流量或者周期性的数据访问是命中率会急剧下降。</li><li><em>Least frequently used (LFU)</em> 最近最少频率使用，他的核心思想是【如果数据过去被多次访问，那么将来被访问的概率也更大】，LFU的实现需要为每个缓存数据维护一个引用计数，最后基于访问数量进行数据淘汰操作，因此实现较为复杂。LFU算法的效率通常高于LRU，能较好的介君突发流量或周期性访问问题，但是由于LFU需要一定时间累积自己的访问频率，因此无法应对数据访问方式的改变。</li><li>更多的缓存淘汰算法有兴趣的同学可点击<a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Segmented_LRU_(SLRU)" target="_blank" rel="noopener">传送门</a>。Caffeine的缓存淘汰是通过一种叫做W-TinyLFU的数据结构实现的，这是一种对LRU和LFU进行了组合优化的算法，下图给出了W-TinyLFU相对其他几种算法的表现，可以看出W-TinyLFU在数据查询、搜索、分析等场景均有优异的表现，更详细的性能测试可以点击<a href="https://github.com/ben-manes/caffeine/wiki/Benchmarks" target="_blank" rel="noopener">传送门</a>。<img src="https://i.loli.net/2020/01/18/frEtxY4cLGkFsiA.png" srcset="/img/loading.gif" alt="image _1_.png"><img src="https://i.loli.net/2020/01/18/B8zVXarIJmvAfbZ.png" srcset="/img/loading.gif" alt="image _2_.png"><h3 id="W-TinyLFU"><a href="#W-TinyLFU" class="headerlink" title="W-TinyLFU"></a>W-TinyLFU</h3>Window TinyLFU主要由以下三个部分组成：<br><img src="https://i.loli.net/2020/01/18/45Y9iACz8OgJHZd.png" srcset="/img/loading.gif" alt="未命名表单.png"></li><li><em>准入窗口（Admission Window</em> 也称伊甸区，是一个较小的LRU队列，其容量只有缓存大小的1%，这个窗口的作用主要是为了保护一些新进入缓存的数据，给他们一定的成长时间来积累自己的使用频率，避免被快速淘汰掉，同时这个窗口也可以过滤掉一些突发流量。</li><li><em>频次过滤器（TinyLFU</em> 是Caffeine数据淘汰策略的核心所在，他依赖CountMin Sketch非精确的记录数据的历史访问次数，从而决定主缓存区数据的淘汰策略，这个数据结构用很小的成本完成了缓存数据访问频次的记录和查找。</li><li><em>主缓存区（Main region</em> 用于存放大部分的缓存数据，数据结构为一个分段LRU队列（SLRU），包括ProtectedDeque和ProbationDeque两部分，其中ProtectedDeque的大小占总容量的80%，该部分使用TinyLFU的Adminsion策略进行数据的淘汰，一些访问频次很低的数据可以被快速淘汰掉，避免了主缓存区被新缓存污染。<h3 id="CountMin-Sketch"><a href="#CountMin-Sketch" class="headerlink" title="CountMin Sketch"></a>CountMin Sketch</h3>LFU算法实现的关键在于如何能高效的保存和读取数据最近的访问频次信息，通常的做法是使用popularity sketch(一种概率数据结构)来识别数据的”命中”事件，从而记录数据的访问次数。CountMin-Sketch便是其中的一种，他是通过一个计数矩阵和多个哈希算法实现的，如图所示：<br><img src="https://i.loli.net/2020/01/18/nMVBZcibk7jLrYy.png" srcset="/img/loading.gif" alt="未命名表单 _1_.png"><br>CountMin Sketch的原理类似于布隆过滤器，也是一种概率型的数据结构。其中不同的row对应着不同的哈希算法，depth大小代表着哈希算法的数量，width则表示数据可哈希的范围。当记录某个指定key的访问次数时，分别使用不同的哈希算法在其对应的row上做哈希操作，如果命中了某一个数据格，则将该数据格的引用计数+1。当查询某个指定key的访问次数时，经过哈希定位到具体的多个数据格后，返回最小的数量计为该数据的访问次数。使用多个哈希算法可以降低哈希碰撞带来的数据不准确的概率，宽度上的增加可以提高key的哈希范围，减少碰撞的概率，因此我们可以通过调整矩阵的width和depth达到算法在空间、效率和哈希碰撞产生的错误率之间平衡的目的。Caffeine中的CountMin Sketch是通过四种哈希算法和一个long型数组实现的，具体的实现方法可以参考咖啡拿铁大神的文章——深入解密来自未来的缓存-Caffeine，这里就不再赘述了。<h3 id="淘汰过程"><a href="#淘汰过程" class="headerlink" title="淘汰过程"></a>淘汰过程</h3><img src="https://i.loli.net/2020/01/18/v6xcKszZ8rV49TI.png" srcset="/img/loading.gif" alt="未命名表单 _2_.png"></li></ul><ol><li>所有进入缓存区的数据会首先被add进Eden区，当该队列长度达到容量限制后，会触发Eden区的淘汰操作，超出的entries会被下放至主缓存区的Probation队列，这些数据被称为Candidate。</li><li>进入Probation队列的数据如果在没有被主缓存区淘汰之前获得了一次access，该节点会被add进Protected队列，这个过程称之为Node Promotion。</li><li>Protecte队列如果达到其容量限制会触发Node Demotion过程，队列首部的元素会被peek出并下放到Probation队列。</li><li>主缓存区的大小(Probation的大小 + Protected的大小)达到了其容量限制会触发主缓存区的数据淘汰，Probation会被优先选择为淘汰队列，如果Probation为空，则选择Protected为淘汰队列。</li><li>分别选取淘汰队列的首部元素作为受害者(victim)，尾部元素作为竞争者(candidate)，通过对比两者的访问频次选择最终的淘汰者，其中访问频次通过CountMin Sketch获得。<blockquote><p>这里Caffeine对于竞争者的淘汰并不只是简单的判断其访问频次小于或等于受害者，而是加入了以下逻辑：</p></blockquote></li></ol><ul><li>如果竞争者的访问频次大于5且小于或等于受害者频次，随机淘汰，这么做的原因主要是为了一定程度的避免哈希碰撞引起的受害者访问频次非自然增长，从而导致新数据无法被写入主缓存区。</li><li>如果竞争者的访问频次小于等于5则直接淘汰竞争者，这是因为TinyLFU中记录数据的访问频次最大值为15，当超过这个最大值触发全局的reset后只有7，因此如果不加一个数据预热的过程，可能会导致一个频率较低的攻击者因为随机淘汰策略挤掉了热点数据。<br>` boolean admit(K candidateKey, K victimKey) {<br>  int victimFreq = frequencySketch().frequency(victimKey);<br>  int candidateFreq = frequencySketch().frequency(candidateKey);<br>  if (candidateFreq &gt; victimFreq) {<pre><code>return true;</code></pre>  } else if (candidateFreq &lt;= 5) {<pre><code>return false;</code></pre>  }<br>  int random = ThreadLocalRandom.current().nextInt();<br>  return ((random &amp; 127) == 0);<br>} `</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2019/06/08/hello-world/"/>
    <url>/2019/06/08/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
