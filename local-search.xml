<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>此刻，我站在这里不是因为我需要结婚，是因为我想与你共度余生！</title>
    <link href="/2020/02/04/%E4%B8%80%E5%B0%81%E5%91%8A%E7%99%BD%E4%BF%A1%EF%BC%81/"/>
    <url>/2020/02/04/%E4%B8%80%E5%B0%81%E5%91%8A%E7%99%BD%E4%BF%A1%EF%BC%81/</url>
    
    <content type="html"><![CDATA[<blockquote><p><strong>此刻，我站在这里不是因为我需要结婚，是因为我想与你共度余生，此刻你看到的是一卷回忆，亦是一份告白。这份信一共由2976个汉字组成，代表着今天是我们在一起的第2976天，这份信读完大约需要9分钟，代表着今年是我们在一起的第九年，这份信的浏览次数只有1，代表着你是我生命中的唯一。</strong></p></blockquote><h1 id="故事的起点"><a href="#故事的起点" class="headerlink" title="故事的起点"></a>故事的起点</h1><p>让时间回到2011年的初冬，那个时候我刚来到北京，第一次离开家独自生活，面对完全陌生的环境我各种不适应，甚至哭过，除了和家人通电话，每天晚上和你在QQ上聊天是我唯一的温暖。12月12日，我终于鼓足勇于向你表白，当听到你肯定的回答后仿佛整个冬天的阴霾都消散了，我们的幸福就此开始。</p><h1 id="难熬的异地"><a href="#难熬的异地" class="headerlink" title="难熬的异地"></a>难熬的异地</h1><p>北京到武汉相隔1156公里，大一到大四需要整整4年，空间和时间加起来考验着我们的爱情，异地的恋爱的确很苦，争吵、猜疑、赌气<br>记得有一次你来北京找我，回去的那天你却坐在火车站的台阶上哭着死活不肯走，可是第二天的票早就卖完了，我只能疯狂的刷12306，也许是冥冥中有天意，竟然真的被我刷到了一张票，<br>后来经常有朋友问我说，四年异地你们究竟是怎么坚持下来的，我每次都只是笑一笑说我也不知道为什么，其实我心里的答案很简单，只是因为我喜欢你。</p><h1 id="固执的坚持"><a href="#固执的坚持" class="headerlink" title="固执的坚持"></a>固执的坚持</h1><p>大四的时候我们都拿到了保送研究生的资格，幸运那一年放开了保送外校政策，可以自由申请学校，不幸的是我因为当时英语六级没过导致了不能</p><h1 id="幸福的时光"><a href="#幸福的时光" class="headerlink" title="幸福的时光"></a>幸福的时光</h1><h1 id="艰难的选择"><a href="#艰难的选择" class="headerlink" title="艰难的选择"></a>艰难的选择</h1><h1 id="重要的决定"><a href="#重要的决定" class="headerlink" title="重要的决定"></a>重要的决定</h1><h1 id="此刻"><a href="#此刻" class="headerlink" title="此刻"></a>此刻</h1>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>一起做的饭🍜，一起长的肉🐷</title>
    <link href="/2020/01/19/%E4%B8%80%E8%B5%B7%E5%81%9A%E9%A5%AD%F0%9F%8D%9C%EF%BC%8C%E4%B8%80%E8%B5%B7%E5%8F%98%E8%83%96%F0%9F%90%B7%E7%9A%84%E6%97%A5%E5%AD%90/"/>
    <url>/2020/01/19/%E4%B8%80%E8%B5%B7%E5%81%9A%E9%A5%AD%F0%9F%8D%9C%EF%BC%8C%E4%B8%80%E8%B5%B7%E5%8F%98%E8%83%96%F0%9F%90%B7%E7%9A%84%E6%97%A5%E5%AD%90/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>我们毕业啦🎓🎉</title>
    <link href="/2020/01/19/%E6%88%91%E4%BB%AC%E6%AF%95%E4%B8%9A%E5%95%A6%F0%9F%8E%93%F0%9F%8E%89/"/>
    <url>/2020/01/19/%E6%88%91%E4%BB%AC%E6%AF%95%E4%B8%9A%E5%95%A6%F0%9F%8E%93%F0%9F%8E%89/</url>
    
    <content type="html"><![CDATA[<blockquote><p><strong>岁月你别催，该来的我不推，岁月你别催，走远的仍要追，眼前这些恍如昨日的画面，是否还停留在你的眼前，你又是否意识到她也会像那时钟的不停滴答声渐行渐远。2018年的盛夏，我们告别了武汉、我们告别了校园、我们告别了青春，我们毕业了。</strong></p></blockquote><p>毕业那天我们带着相机踏遍了校园的每个角落，仔细回想着三年时光赠予我们的每段记忆。我们拍了很多照片，在梅操、在奥场、在樱顶、在校门、在教室······，贪婪的我们好想把这一切的美好都记录下来，镜头可以定格时间，我们却永远回不去那逝去的青春。</p><p><img src="https://i.loli.net/2020/01/20/JIgwzQjR1sfNGKY.jpg" srcset="/img/loading.gif" alt="IMG_0842.jpg"><br><img src="https://i.loli.net/2020/01/20/fqOjvEKeL3BZQnr.jpg" srcset="/img/loading.gif" alt="IMG_0839.jpg"><br><img src="https://i.loli.net/2020/01/20/98z4dZDnmJbBoFt.jpg" srcset="/img/loading.gif" alt="IMG_0840.jpg"><br><img src="https://i.loli.net/2020/01/20/qFVWgyXj1Qt8KJo.jpg" srcset="/img/loading.gif" alt="IMG_0841.jpg"><br><img src="https://i.loli.net/2020/01/20/OI9hxlQ84morLTq.jpg" srcset="/img/loading.gif" alt="IMG_0852.jpg"><br><img src="https://i.loli.net/2020/01/20/I92D3HT8Nrkqhjb.jpg" srcset="/img/loading.gif" alt="IMG_0883.jpg"><br><img src="https://i.loli.net/2020/01/20/PcvpyGBOxbEoT83.jpg" srcset="/img/loading.gif" alt="IMG_0838.jpg"><br><img src="https://i.loli.net/2020/01/20/AiLkEsc8BJZmaew.jpg" srcset="/img/loading.gif" alt="IMG_0879.jpg"><br><img src="https://i.loli.net/2020/01/20/AsvOq4ulnWVwZkE.jpg" srcset="/img/loading.gif" alt="IMG_0846.jpg"><br><img src="https://i.loli.net/2020/01/20/JhAuof3pqY5XEaN.jpg" srcset="/img/loading.gif" alt="IMG_0882.jpg"><br><img src="https://i.loli.net/2020/01/20/6Lm4tvquN8CbnGy.jpg" srcset="/img/loading.gif" alt="IMG_0885.jpg"><br><img src="https://i.loli.net/2020/01/20/DuEyPmlitdcA4Zs.jpg" srcset="/img/loading.gif" alt="IMG_0884.jpg"><br><img src="https://i.loli.net/2020/01/20/owIARiO8eE1UgmT.jpg" srcset="/img/loading.gif" alt="IMG_0901.jpg"><br><img src="https://i.loli.net/2020/01/20/zjeWPcM7V2xNTQm.jpg" srcset="/img/loading.gif" alt="P1010216.jpg"><br><img src="https://i.loli.net/2020/01/20/VQwzYLAtJXldNiM.jpg" srcset="/img/loading.gif" alt="P1010651.jpg"><br><img src="https://i.loli.net/2020/01/20/4xoZXOQLV56ipKc.jpg" srcset="/img/loading.gif" alt="IMG_0886.jpg"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>The Trip To Europe</title>
    <link href="/2020/01/19/The-Trip-To-Europe/"/>
    <url>/2020/01/19/The-Trip-To-Europe/</url>
    
    <content type="html"><![CDATA[<h1 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h1><p>2019年初你最好的朋友刘博士去了比利时🇧🇪留学，所以你们约定要在欧洲一起旅行。计划容易，实施难，况且我们还是这种毫无经验没出过国的小白，不过我们并没有迟疑，还是坚决的行动了起来，准备的细节先不写了，后面你来补充吧～</p><h1 id="出发-浦东国际机场"><a href="#出发-浦东国际机场" class="headerlink" title="出发 浦东国际机场"></a>出发 浦东国际机场</h1><h1 id="短暂停留-香港国际机场（中国香港🇨🇳🇭🇰）"><a href="#短暂停留-香港国际机场（中国香港🇨🇳🇭🇰）" class="headerlink" title="短暂停留 香港国际机场（中国香港🇨🇳🇭🇰）"></a>短暂停留 香港国际机场（中国香港🇨🇳🇭🇰）</h1><p>一开始买到在香港中转的机票而且还是国泰航空其实我内心是有点惶恐的，因为那段时间香港持续发生暴动，机场更是连续好几日被占领，最严重的时候直接导致了整个机场的瘫痪，不过相比其他上万的机票我们决定还是赌一赌，毕竟也只有两个小时而已。</p><h1 id="第一站：布鲁塞尔（比利时🇧🇪）"><a href="#第一站：布鲁塞尔（比利时🇧🇪）" class="headerlink" title="第一站：布鲁塞尔（比利时🇧🇪）"></a>第一站：布鲁塞尔（比利时🇧🇪）</h1><p>按照计划这里并没有多做停留，刚下飞机就坐着小火车去了根特，虽然刚刚熬了18个小时的飞机，经受着7小时的时差，但第一次迈出国门的我们心情还是无比的兴奋。</p><h1 id="第二站：根特（比利时🇧🇪）"><a href="#第二站：根特（比利时🇧🇪）" class="headerlink" title="第二站：根特（比利时🇧🇪）"></a>第二站：根特（比利时🇧🇪）</h1><h1 id="第三站：布鲁日（比利时🇧🇪）"><a href="#第三站：布鲁日（比利时🇧🇪）" class="headerlink" title="第三站：布鲁日（比利时🇧🇪）"></a>第三站：布鲁日（比利时🇧🇪）</h1><h1 id="第四站：奥斯坦德（比利时🇧🇪）"><a href="#第四站：奥斯坦德（比利时🇧🇪）" class="headerlink" title="第四站：奥斯坦德（比利时🇧🇪）"></a>第四站：奥斯坦德（比利时🇧🇪）</h1><h1 id="第五站：布拉格（捷克🇨🇿）"><a href="#第五站：布拉格（捷克🇨🇿）" class="headerlink" title="第五站：布拉格（捷克🇨🇿）"></a>第五站：布拉格（捷克🇨🇿）</h1><h1 id="第六站：布达佩斯（匈牙利🇭🇺）"><a href="#第六站：布达佩斯（匈牙利🇭🇺）" class="headerlink" title="第六站：布达佩斯（匈牙利🇭🇺）"></a>第六站：布达佩斯（匈牙利🇭🇺）</h1><h1 id="第七站：巴黎（法国🇫🇷）"><a href="#第七站：巴黎（法国🇫🇷）" class="headerlink" title="第七站：巴黎（法国🇫🇷）"></a>第七站：巴黎（法国🇫🇷）</h1><h1 id="第八站：布鲁塞尔（比利时🇧🇪）"><a href="#第八站：布鲁塞尔（比利时🇧🇪）" class="headerlink" title="第八站：布鲁塞尔（比利时🇧🇪）"></a>第八站：布鲁塞尔（比利时🇧🇪）</h1><h1 id="第九站：根特（比利时🇧🇪）"><a href="#第九站：根特（比利时🇧🇪）" class="headerlink" title="第九站：根特（比利时🇧🇪）"></a>第九站：根特（比利时🇧🇪）</h1><h1 id="短暂停留：阿布扎比（沙特联合酋长国🇦🇪）"><a href="#短暂停留：阿布扎比（沙特联合酋长国🇦🇪）" class="headerlink" title="短暂停留：阿布扎比（沙特联合酋长国🇦🇪）"></a>短暂停留：阿布扎比（沙特联合酋长国🇦🇪）</h1><h1 id="回家"><a href="#回家" class="headerlink" title="回家"></a>回家</h1>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Caffeine缓存详解</title>
    <link href="/2020/01/18/Caffeine%E7%BC%93%E5%AD%98%E8%AF%A6%E8%A7%A3/"/>
    <url>/2020/01/18/Caffeine%E7%BC%93%E5%AD%98%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Caffeine是一款基于Java8开发的，高性能的，接近最优的本地缓存库，出自于Benjamin Manes大神之手，大家熟悉的Spring4.3+和SpringBoot1.4+缓存的实现便是基于Caffeine。本文将从淘汰策略、过期策略、并发控制等方面为大家揭开Caffeine的神秘面纱,由于笔者自身水平有限，如果有不对或者任何建议欢迎批评和指正</p><h1 id="淘汰策略（Size-Based）"><a href="#淘汰策略（Size-Based）" class="headerlink" title="淘汰策略（Size-Based）"></a>淘汰策略（Size-Based）</h1><p>&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp缓存命中率是衡量缓存系统优劣的重要指标，缓存通过保存最近使用或经常使用的数据于速度较快的介质中以提高数据的访问速度，缓存空间被填满后，会面临如何选择丢弃数据为新数据腾出空间的问题，因此选择合适的缓存淘汰算法会直接影响缓存的命中率。常用的缓存算法有：</p><ul><li><em>First in first out (FIFO)</em> 顾名思义，就是一个FIFO队列，先进入缓存的先被淘汰，忽略数据访问频率和次数信息。较为原始，命中率很低。</li><li><em>Least recently used (LRU)</em> 最近最少被使用算法，其核心思想是【如果数据最近被访问过，那么将来被访问的概率也更大】，忽略了数据的访问次数，最常见的实现是维护一个链表，新数据插入到链表尾部，命中缓存的数据重新移至队尾，队列满后移出队首元素。LRU算法在有热点数据的情况下效率很好，但是如果面临突然流量或者周期性的数据访问是命中率会急剧下降。</li><li><em>Least frequently used (LFU)</em> 最近最少频率使用，他的核心思想是【如果数据过去被多次访问，那么将来被访问的概率也更大】，LFU的实现需要为每个缓存数据维护一个引用计数，最后基于访问数量进行数据淘汰操作，因此实现较为复杂。LFU算法的效率通常高于LRU，能较好的介君突发流量或周期性访问问题，但是由于LFU需要一定时间累积自己的访问频率，因此无法应对数据访问方式的改变。</li><li>更多的缓存淘汰算法有兴趣的同学可点击<a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Segmented_LRU_(SLRU)" target="_blank" rel="noopener">传送门</a>。Caffeine的缓存淘汰是通过一种叫做W-TinyLFU的数据结构实现的，这是一种对LRU和LFU进行了组合优化的算法，下图给出了W-TinyLFU相对其他几种算法的表现，可以看出W-TinyLFU在数据查询、搜索、分析等场景均有优异的表现，更详细的性能测试可以点击<a href="https://github.com/ben-manes/caffeine/wiki/Benchmarks" target="_blank" rel="noopener">传送门</a>。<img src="https://i.loli.net/2020/01/18/frEtxY4cLGkFsiA.png" srcset="/img/loading.gif" alt="image _1_.png"><img src="https://i.loli.net/2020/01/18/B8zVXarIJmvAfbZ.png" srcset="/img/loading.gif" alt="image _2_.png"><h2 id="W-TinyLFU"><a href="#W-TinyLFU" class="headerlink" title="W-TinyLFU"></a>W-TinyLFU</h2>Window TinyLFU主要由以下三个部分组成：<br><img src="https://i.loli.net/2020/01/18/45Y9iACz8OgJHZd.png" srcset="/img/loading.gif" alt="未命名表单.png"></li><li><em>准入窗口（Admission Window</em> 也称伊甸区，是一个较小的LRU队列，其容量只有缓存大小的1%，这个窗口的作用主要是为了保护一些新进入缓存的数据，给他们一定的成长时间来积累自己的使用频率，避免被快速淘汰掉，同时这个窗口也可以过滤掉一些突发流量。</li><li><em>频次过滤器（TinyLFU</em> 是Caffeine数据淘汰策略的核心所在，他依赖CountMin Sketch非精确的记录数据的历史访问次数，从而决定主缓存区数据的淘汰策略，这个数据结构用很小的成本完成了缓存数据访问频次的记录和查找。</li><li><em>主缓存区（Main region</em> 用于存放大部分的缓存数据，数据结构为一个分段LRU队列（SLRU），包括ProtectedDeque和ProbationDeque两部分，其中ProtectedDeque的大小占总容量的80%，该部分使用TinyLFU的Adminsion策略进行数据的淘汰，一些访问频次很低的数据可以被快速淘汰掉，避免了主缓存区被新缓存污染。<h2 id="CountMin-Sketch"><a href="#CountMin-Sketch" class="headerlink" title="CountMin Sketch"></a>CountMin Sketch</h2>LFU算法实现的关键在于如何能高效的保存和读取数据最近的访问频次信息，通常的做法是使用popularity sketch(一种概率数据结构)来识别数据的”命中”事件，从而记录数据的访问次数。CountMin-Sketch便是其中的一种，他是通过一个计数矩阵和多个哈希算法实现的，如图所示：<br><img src="https://i.loli.net/2020/01/18/nMVBZcibk7jLrYy.png" srcset="/img/loading.gif" alt="未命名表单 _1_.png"><br>CountMin Sketch的原理类似于布隆过滤器，也是一种概率型的数据结构。其中不同的row对应着不同的哈希算法，depth大小代表着哈希算法的数量，width则表示数据可哈希的范围。当记录某个指定key的访问次数时，分别使用不同的哈希算法在其对应的row上做哈希操作，如果命中了某一个数据格，则将该数据格的引用计数+1。当查询某个指定key的访问次数时，经过哈希定位到具体的多个数据格后，返回最小的数量计为该数据的访问次数。使用多个哈希算法可以降低哈希碰撞带来的数据不准确的概率，宽度上的增加可以提高key的哈希范围，减少碰撞的概率，因此我们可以通过调整矩阵的width和depth达到算法在空间、效率和哈希碰撞产生的错误率之间平衡的目的。Caffeine中的CountMin Sketch是通过四种哈希算法和一个long型数组实现的，具体的实现方法可以参考咖啡拿铁大神的文章——深入解密来自未来的缓存-Caffeine，这里就不再赘述了。<h2 id="淘汰过程"><a href="#淘汰过程" class="headerlink" title="淘汰过程"></a>淘汰过程</h2><img src="https://i.loli.net/2020/01/18/v6xcKszZ8rV49TI.png" srcset="/img/loading.gif" alt="未命名表单 _2_.png"></li></ul><ol><li>所有进入缓存区的数据会首先被add进Eden区，当该队列长度达到容量限制后，会触发Eden区的淘汰操作，超出的entries会被下放至主缓存区的Probation队列，这些数据被称为Candidate。</li><li>进入Probation队列的数据如果在没有被主缓存区淘汰之前获得了一次access，该节点会被add进Protected队列，这个过程称之为Node Promotion。</li><li>Protecte队列如果达到其容量限制会触发Node Demotion过程，队列首部的元素会被peek出并下放到Probation队列。</li><li>主缓存区的大小(Probation的大小 + Protected的大小)达到了其容量限制会触发主缓存区的数据淘汰，Probation会被优先选择为淘汰队列，如果Probation为空，则选择Protected为淘汰队列。</li><li>分别选取淘汰队列的首部元素作为受害者(victim)，尾部元素作为竞争者(candidate)，通过对比两者的访问频次选择最终的淘汰者，其中访问频次通过CountMin Sketch获得。<blockquote><p>这里Caffeine对于竞争者的淘汰并不只是简单的判断其访问频次小于或等于受害者，而是加入了以下逻辑：</p><ul><li>如果竞争者的访问频次大于5且小于或等于受害者频次，随机淘汰，这么做的原因主要是为了一定程度的避免哈希碰撞引起的受害者访问频次非自然增长，从而导致新数据无法被写入主缓存区。</li><li>如果竞争者的访问频次小于等于5则直接淘汰竞争者，这是因为TinyLFU中记录数据的访问频次最大值为15，当超过这个最大值触发全局的reset后只有7，因此如果不加一个数据预热的过程，可能会导致一个频率较低的攻击者因为随机淘汰策略挤掉了热点数据。</li></ul></blockquote></li></ol><pre><code class="java">boolean admit(K candidateKey, K victimKey) {    int victimFreq = frequencySketch().frequency(victimKey);    int candidateFreq = frequencySketch().frequency(candidateKey);    if (candidateFreq &gt; victimFreq) {      return true;    } else if (candidateFreq &lt;= 5) {      return false;    }    int random = ThreadLocalRandom.current().nextInt();    return ((random &amp; 127) == 0);}</code></pre><h1 id="过期策略（Time-Based）"><a href="#过期策略（Time-Based）" class="headerlink" title="过期策略（Time-Based）"></a>过期策略（Time-Based）</h1><p>缓存数据过期清理的必要性和重要性不仅仅体现在应用场景的要求上，对于缓存本身，及时清理掉过期数据可以节省空间，降低缓存的维护成本，提高缓存性能，缓存过期清理的方式可以分为以下两种（是我按照自己的理解分的，没有资料依据，有不当之处望大家指正）：</p><ul><li><p>_访问清理_，即每次访问某个具体的缓存数据时判断其是否过期然后执行相应的操作。这种策略的优点就是实现简单，缺点是缓存的过期依赖于缓存的访问，会造成过期数据污染缓存区现象的发生，如果一个数据过期后没有被再次访问，那么他可能会长期存在于缓存中，直到淘汰策略将其移除。</p></li><li><p>_全局清理_，即在某些特定的时期全局性的扫描缓存区，清理掉过期数据。这种方式的优点是可以及时清理掉一些过期的数据，不必依赖数据的访问。缺点是实现成本高，需要使用额外的数据结构去维护一个过期队列，实现复杂，除此之外全局清理的发生时间也是一个棘手的问题。</p><h2 id="清理策略"><a href="#清理策略" class="headerlink" title="清理策略"></a>清理策略</h2><p>Caffeine中的对于访问清理和全局清理都有支持，对于访问清理的实现方式如下图所示，因为Caffeine缓存区的实现是一个LRU队列，本身就维护了数据访问的时间顺序，因此不必使用额外的数据结构进行存储，每次只用peek出缓存队列的首部元素对其进行过期判断即可。</p><pre><code class="java">void expireAfterAccessEntries(AccessOrderDeque&lt;Node&lt;K, V&gt;&gt; accessOrderDeque, long now) {  long duration = expiresAfterAccessNanos();  for (;;) {    Node&lt;K, V&gt; node = accessOrderDeque.peekFirst();    if ((node == null) || ((now - node.getAccessTime()) &lt; duration)) {      return;    }    evictEntry(node, RemovalCause.EXPIRED, now);  }}</code></pre><p>对于全局清理而言主要有两个要解决的问题点，即如何选择清理时间和如何快速找到过期数据并移除。我们首先来看第一个问题，通常来讲有两种方式，一是依赖缓存的淘汰策略，缓存区达到容量限制后发生缓存淘汰时触发一次缓存过期清理，二是开启一个清理线程定期的执行过期清理工作。Caffeine中选择的第二种方式，不同的是这里的实现并不是通过一个轮询线程定期执行，而是由缓存的读写触发的，具体的触发方式和触发规则将在下一节【并发控制】里详细讲解。解决了如何选择清理时间的问题我们再来看如何能快速找到过期数据，通常的做法是维护一个基于过期时间的优先队列，这样做的复杂度是O(lgn)，Caffeine中采用的是Kafka中的时间轮<a href="http://www.cs.columbia.edu/~nahum/w6998/papers/sosp87-timing-wheels.pdf" target="_blank" rel="noopener">hierarchical timing wheels</a>方法，他的插入删除时间复杂度都为O(1)，相信做过定时任务调度的同学对这个数据结构一定不陌生，这里只做一点简单的介绍，想要深入了解的同学可以点击<a href="https://www.confluent.io/blog/apache-kafka-purgatory-hierarchical-timing-wheels/" target="_blank" rel="noopener">传送门</a>。</p><h3 id="时间轮（Timing-Wheels）"><a href="#时间轮（Timing-Wheels）" class="headerlink" title="时间轮（Timing Wheels）"></a>时间轮（Timing Wheels）</h3><p><img src="https://i.loli.net/2020/01/18/9aLn6PFjhK8cB3q.png" srcset="/img/loading.gif" alt="185214690.png"><br>时间轮是一个由时间插槽组成的环状数组，插槽由一组同样时间范围内的定时任务组成。每一个插槽代表一个时间间隔(u)，时间轮由n个插槽组成，因此一个时间轮所能承载的调度时间是u*n。时间轮中时间指针(ticks)用于标记时间，每次转动一个插槽的间隔，ticks指向的插槽代表当前插槽内的所有任务过期，清空当前插槽，插入任务时，基于当前时间算出ticks所在的插槽，再根据任务的过期时间插入相应的插槽即可，可以看出时间轮对于任务的插入和删除(过期)操作时间复杂度都是O(1)。单个时间轮所能代表的时间是有限的，当一个任务的过期时间超过了时间轮所能表示的调度范围时，单个时间轮就无法胜任了，当然我们可以选择像HashMap一样做扩容，重新划分时间间隔或增加插槽数，显然成本太高，不能接受，因此引进了层级时间轮的概念，更通俗一点就是多来几个轮子，每个时间轮代表的一种时间间隔，如果上层时间轮的精度太粗不能满足要求，则交给下一级的时间轮处理，直至找到满足要求的时间间隔要求的时间轮，此时任务插入的时间成本变成了O(m)，其中m等于时间轮的个数，时间轮的个数不可能很大，这是可以接受的。插槽内定时任务的存储是用一个双向链表实现的，这样设计的好处是如果我们持有列表中一个节点的引用时可以以O(1)的时间复杂度对该节点做删除或插入操作。</p><h1 id="并发控制（Concurrency-Control）"><a href="#并发控制（Concurrency-Control）" class="headerlink" title="并发控制（Concurrency-Control）"></a>并发控制（Concurrency-Control）</h1><p>缓存的并发控制是一个比较头疼的问题，因为缓存的淘汰策略、过期策略等等都会涉及到了对同一块缓存区内容的修改，最简单省事的办法无非就是给缓存区加锁，分段锁是一种比较通用的解决方案，ConcurrentyHashMap的实现(Java8之前)就是基于分段锁，然而由于缓存中锁的竞争主要发生在一些热点数据上，因此分段锁带来的收益也是有限的。Caffeine中采用了缓冲队列回放机制来减轻并发带来的锁竞争问题，同时对于缓存而言读操作是远远大于写操作的，因此Caffeine中对于读写的缓冲队列也采用了不同的实现思路和方式，下面详细讨论。</p><h2 id="缓冲队列——读"><a href="#缓冲队列——读" class="headerlink" title="缓冲队列——读"></a>缓冲队列——读</h2><p>Caffeine中缓存每次的读操作都会先被写入缓冲队列，其底层的数据结构是一个<a href="https://github.com/ben-manes/caffeine/issues/161" target="_blank" rel="noopener">striped ring buffer</a>，这里的striped是指一种通过哈希获取锁的算法，对于同一个key（Java中可能对象地址不同）哈希后获得的将是同一个锁对象，Caffeine基于striped hash后的key分配相应的ring buffer，值得注意的是这里的key并不是缓存数据的key，而是线程本身，这样设计的好处是可以对热点数据访问引起的激增流量起到削峰作用。写入缓存成功后会基于一定的条件判断是否需要触发一个异步的缓存区调度任务，代码如下。可以看到当ring buffer满了之后并且调度状态满足一定的条件才会触发，如果当前ring buffer满之后，后续写入该队列的读操作会被直接被丢弃，这种信息的缺失并不会产生很大的影响，因为TinyLFU可以记录哪些是热点数据，这里状态机之间的流转如图所示，具体的状态机转移过程情况较多比较复杂，有兴趣的同学可以去看源码。</p><pre><code class="java">void afterRead(Node&lt;K, V&gt; node, long now, boolean recordHit) {  if (recordHit) {    statsCounter().recordHits(1);  }  boolean delayable = skipReadBuffer() || (readBuffer.offer(node) != Buffer.FULL);  if (shouldDrainBuffers(delayable)) {    scheduleDrainBuffers();  }  refreshIfNeeded(node, now);}boolean shouldDrainBuffers(boolean delayable) {switch (drainStatus()) {  case IDLE:    return !delayable;  case REQUIRED:    return true;  case PROCESSING_TO_IDLE:  case PROCESSING_TO_REQUIRED:    return false;  default:    throw new IllegalStateException();}}</code></pre><p><img src="https://i.loli.net/2020/01/18/kQbc8Tiu1LBoX9m.png" srcset="/img/loading.gif" alt="未命名表单 _3_.png"><br><img src="https://i.loli.net/2020/01/18/l29KMm3RznsywqX.png" srcset="/img/loading.gif" alt="185377099.png"></p><h2 id="缓冲队列——写"><a href="#缓冲队列——写" class="headerlink" title="缓冲队列——写"></a>缓冲队列——写</h2><p>Caffeine认为写的操作远小于读，因此所有的写操作共享同一个缓冲队列，这里的队列一个多生产者单消费者模型，具体的实现是用了<a href="https://github.com/JCTools/JCTools/wiki/Which-Queue-Should-I-Use%3F" target="_blank" rel="noopener">JCtools</a>里的无锁MPSC(Multi Producer Single Consumer)自动扩容队列，由于没有锁因此效率很高。写操作的丢失是能被容许的，因此Caffeine中每次写操作都会触发一次缓存区调度任务。缓存区的任务回放(读和写都有)和缓存数据的写入会产生竞态条件，可能会导致对某个缓存数据的增删改查操作不能被有序的执行，从而产生<a href="https://stackoverflow.com/questions/5900165/what-is-the-difference-between-garbage-and-dangling-references" target="_blank" rel="noopener">悬空索引</a>的问题，Caffenie通过引入了状态机定义节点的生命周期来解决这个问题。Alive状态代表该节点还在缓存中，Retired状态代表节点不在缓存中但是正在被淘汰策略清除，Dead状态代表该节点已经被移出缓存区了。<br><img src="https://i.loli.net/2020/01/18/gG7wn8JVdBxYeHX.png" srcset="/img/loading.gif" alt="1.png"><br><img src="https://i.loli.net/2020/01/18/5MEfRmiLOArsZuP.png" srcset="/img/loading.gif" alt="2.png"></p><h2 id="缓冲队列任务调度（Maintenance-Work）"><a href="#缓冲队列任务调度（Maintenance-Work）" class="headerlink" title="缓冲队列任务调度（Maintenance Work）"></a>缓冲队列任务调度（Maintenance Work）</h2><p>上面提到读写操作都会触发缓存区的任务调度，那这个任务调度到底是干了那些事情呢，上代码。可以看到Caffeine中的缓存区任务调度(scheduleDrainBuffers)实际上是异步执行了一个叫做执行清理的任务(PerformCleanupTask)，这里的线程池采用了ForkJoinPool实现。继续往下可以看到清理任务其实最终执行的是maintenance方法中的内容，执行之前会获取一个叫做evictionLock的锁，这里其实已经可以猜到这部分的主要工作肯定是和缓存淘汰有关，查看maintenance内容也验证了前面的猜想。至此可以总结出Caffeine中引用淘汰、容量限制淘汰、缓存过期淘汰是由缓存的读写操作经过一定规则计算后触发的，这也解释了上述遗留的缓存过期淘汰发生时间问题。</p><pre><code class="java">void scheduleDrainBuffers() {  if (drainStatus() &gt;= PROCESSING_TO_IDLE) {    return;  }  if (evictionLock.tryLock()) {    try {      int drainStatus = drainStatus();      if (drainStatus &gt;= PROCESSING_TO_IDLE) {        return;      }      lazySetDrainStatus(PROCESSING_TO_IDLE);      executor().execute(drainBuffersTask);    } catch (Throwable t) {      logger.log(Level.WARNING, &quot;Exception thrown when submitting maintenance task&quot;, t);      maintenance();    } finally {      evictionLock.unlock();    }  }}final class PerformCleanupTask extends ForkJoinTask&lt;Void&gt; implements Runnable {  @Override  public void run() {    performCleanUp();  }}</code></pre><pre><code class="java">void scheduleDrainBuffers() {  if (drainStatus() &gt;= PROCESSING_TO_IDLE) {    return;  }  if (evictionLock.tryLock()) {    try {      int drainStatus = drainStatus();      if (drainStatus &gt;= PROCESSING_TO_IDLE) {        return;      }      lazySetDrainStatus(PROCESSING_TO_IDLE);      executor().execute(drainBuffersTask);    } catch (Throwable t) {      logger.log(Level.WARNING, &quot;Exception thrown when submitting maintenance task&quot;, t);      maintenance();    } finally {      evictionLock.unlock();    }  }}final class PerformCleanupTask extends ForkJoinTask&lt;Void&gt; implements Runnable {  @Override  public void run() {    performCleanUp();  }}void performCleanUp(@Nullable Runnable task) {  evictionLock.lock();  try {    maintenance(task);  } finally {    evictionLock.unlock();  }}void maintenance(@Nullable Runnable task) {  lazySetDrainStatus(PROCESSING_TO_IDLE);  try {    drainReadBuffer();    drainWriteBuffer();    if (task != null) {      task.run();    }    drainKeyReferences();    drainValueReferences();    expireEntries();    evictEntries();  } finally {    if ((drainStatus() != PROCESSING_TO_IDLE) || !casDrainStatus(PROCESSING_TO_IDLE, IDLE)) {      lazySetDrainStatus(REQUIRED);    }  }}</code></pre><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>上述章节已经详细的介绍了Caffeine的一些核心能力及其实现原理，除此之外Caffeine还提供了异步刷新、弱引用key、弱软引用value、淘汰监听、打点监控等功能，由于篇幅关系这里也不再多做介绍。说了这么多，那到底Caffeine怎么用呢？是不是还要花时间去熟悉API？我想说这部分大家完全不必担心，因为Caffeine的API是完全参考Google Guava的，如果你有Guava的使用经验切换成本几乎为零，这里贴上一段Caffeine的Cache构建代码，大家可以发现是不是和Guava一模一样。</p><pre><code class="java">public static void main(String[] args) {  Cache&lt;String, Object&gt; manualCache = Caffeine.newBuilder()      .expireAfterWrite(10, TimeUnit.MINUTES)      .expireAfterAccess(1000, TimeUnit.SECONDS)      .maximumSize(10000)      .build();  String key = &quot;learning&quot;;  manualCache.put(key, &quot;caffeine&quot;);  manualCache.get(key, e -&gt; getFromMysql(key));}private static String getFromMysql(String key) {  return &quot;hha&quot;;}</code></pre><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="http://highscalability.com/blog/2016/1/25/design-of-a-modern-cache.html" target="_blank" rel="noopener">Design Of A Modern Cache（Part1）</a><br><a href="http://highscalability.com/blog/2019/2/25/design-of-a-modern-cachepart-deux.html" target="_blank" rel="noopener">Design Of A Modern Cache（Part2）</a><br><a href="http://dimacs.rutgers.edu/~graham/pubs/papers/cmsoft.pdf" target="_blank" rel="noopener">Approximating Data with the Count-Min Data Structure</a><br><a href="http://delivery.acm.org/10.1145/3150000/3149371/a35-einziger.pdf?ip=185.214.167.165&id=3149371&acc=AUTHOR%2DIZED&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E7CF34BA1F19DEFD2&__acm__=1565271897_e54f950aa47c703b62b9e35d55ab2325" target="_blank" rel="noopener">TinyLFU: A Highly Efficient Cache Admission Policy</a><br><a href="https://github.com/ben-manes/caffeine" target="_blank" rel="noopener">https://github.com/ben-manes/caffeine</a><br><a href="https://juejin.im/post/5b8df63c6fb9a019e04ebaf4" target="_blank" rel="noopener">深入解密来自未来的缓存-Caffeine</a><br><a href="https://juejin.im/post/5b7593496fb9a009b62904fa" target="_blank" rel="noopener">你应该知道的缓存进化史</a><br><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies" target="_blank" rel="noopener">Cache Replacement Policies</a><br><a href="https://www.confluent.io/blog/apache-kafka-purgatory-hierarchical-timing-wheels/" target="_blank" rel="noopener">Apache Kafka, Purgatory, and Hierarchical Timing Wheels</a></p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>缓存</tag>
      
      <tag>Caffeine</tag>
      
      <tag>Guava</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
